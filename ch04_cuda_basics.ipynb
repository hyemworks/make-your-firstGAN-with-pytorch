{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch04-cuda-basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOr9VC7U4JZEUiPPZWmrCJu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyemworks/make-your-firstGAN-with-pytorch/blob/main/ch04_cuda_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbMFrDl4kCqW"
      },
      "source": [
        "# **CHAPTER 04 &nbsp;&nbsp;&nbsp;&nbsp;CUDA Basics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBbFpe1ykJqm"
      },
      "source": [
        "## **Numpy VS Python**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8fG6Ud4kc4W"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_n4w7MykoGy"
      },
      "source": [
        "# 정사각행렬의 크기\n",
        "size = 600\n",
        "\n",
        "a = np.random.rand(size,size)\n",
        "b = np.random.rand(size,size) # 0과 1사이의 임의의 값으로 두 넘파이 행렬을 채움."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCoTdeZrk3EX",
        "outputId": "6d872fb4-9c84-46de-eeca-805a75ea47a7"
      },
      "source": [
        "%%timeit\n",
        "# 한 셀에서 시간이 얼마나 오래 걸리는지 표시해줌.\n",
        "\n",
        "# 01. numpy를 사용하는 경우 - 12.1 ms per loop\n",
        "x = np.dot(a,b)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 12.1 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCH-VsMDlGIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b25e5c-48d9-4598-b52e-6044e309d1d9"
      },
      "source": [
        "%%timeit\n",
        "\n",
        "# 02. numpy를 사용하지 않는 경우 - 2min 47s per loop\n",
        "c = np.zeros((size,size))\n",
        "\n",
        "for i in range(size):\n",
        "  for j in range(size):\n",
        "    for k in range(size):\n",
        "      c[i,j] += a[i,k]*b[k,j]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2min 47s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "↪ 간단히 비교해보면, Numpy가 순수 Python보다 **행렬곱 계산**이 훨씬 빠르다는 것을 알 수 있다!"
      ],
      "metadata": {
        "id": "BfERI1NAcC1U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Kis_HPYklz"
      },
      "source": [
        "## **엔비디아 CUDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAWuKPtMYgmC"
      },
      "source": [
        "✅ **NVIDIA, 엔비디아**\n",
        "  - GPU 시장의 리더역할을 하고 있는 기업\n",
        "  - 강력한 하드웨어 가속 기능을 갖춘, 머신러닝 연구에 표준적인 소프트웨어 툴을 제공함.<br>\n",
        "  <br>\n",
        "  🦋 <b>CUDA</b>$^{Compute-Unified-Device-Architecture}$<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;: 엔비디아에서 제공하는 소프트웨어 프레임 워크\n",
        "  <br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;▶ 단점 <br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: 엔비디아의 GPU에서만 동작.<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cf) 경쟁사인 AMD는 최근에서야 필적할 만한 프레임워크를 개발함. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAGmfkWPmJ3y"
      },
      "source": [
        "## **CUDA를 Python에서 사용하기**\n",
        "\n",
        ": Colab 노트북 내 설정방법<br>\n",
        "↪ 상단 메뉴 > [Runtime] > [Change Runtime Type] > [Hardware Accelerator] > **GPU**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor 만들기\n",
        "\n",
        "x = torch.FloatTensor([3.5])\n",
        "print(x.type()) # 데이터 타입 체크"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ET_KQpaKux-",
        "outputId": "f4958ded-0035-4161-d999-d0490b3c675d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAQrA6Whfsm3",
        "outputId": "1db3938e-1d09-4151-86b2-026d2f7c2d37"
      },
      "source": [
        "# GPU에서 tensor 만들기\n",
        "\n",
        "x = torch.cuda.FloatTensor([3.5])\n",
        "print(x.type()) # 데이터 타입 체크\n",
        "print(x.device) # 어떤 장치에 텐서가 올라가 있는지 체크\n",
        "x.device  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.FloatTensor\n",
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU를 통해 텐서 계산\n",
        "\n",
        "y = x*x\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZeKn2ktLwyZ",
        "outputId": "b8f40121-fd2d-4e2b-f87a-df233dcca0c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.2500], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "GPU를 사용함으로써 이득을 얻으려면, 정말 많은 데이터를 각 GPU 코어에 나눠서 투입해야함.<br>\n",
        "➡ 앞에서 했던 행렬곱을 GPU에서 해보자"
      ],
      "metadata": {
        "id": "Jx8GvPl5L-MJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugGriYH2f9lj"
      },
      "source": [
        "aa = torch.cuda.FloatTensor(a)\n",
        "bb = torch.cuda.FloatTensor(b)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Omn3CVgwsJ",
        "outputId": "e7393245-942d-42cd-db1b-b3aa23481874"
      },
      "source": [
        "%%timeit\n",
        "\n",
        "# torch.matmul => pytorch에서 \"행렬곱\"을 하는 명령어\n",
        "\n",
        "cc = torch.matmul(aa,bb)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 480.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 116 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "아래 셀 == 파이토치의 device에 대한 표준적인 코드처리<br>\n",
        "▶ **GPU**를 기본값으로 설정하고, **CUDA가 사용 가능하지 않을 때**에만 **CPU**를 이용함!"
      ],
      "metadata": {
        "id": "byl7uOnPM0zl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8iYJxyfhK1U",
        "outputId": "2e3923da-c57c-47ec-8159-df4a04e8fbf1"
      },
      "source": [
        "## Check if CUDA is available\n",
        "## if yes, set default tensor type to cuda\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "  print(\"using cuda : \", torch.cuda.get_device_name(0))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda :  Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Summary**\n",
        ">✅ **GPU$^{Graphics-Processing-Unit}$, 그래픽 처리 장치** <br>\n",
        ": 많은 수의 연산 코어를 통해 특정한 작업을 빠르게 할 수 있음.<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; ↪ **병렬로 행렬곱을 처리**하는 것 등을 포함하여, 단순 계산에 특화됨.<br>\n",
        ": 그래픽 관련 연산외에도 머신러닝 관련 계산이 빠름.\n",
        "<br>\n",
        "<br>\n",
        "✅ **CUDA$^{Compute-Unified-Device-Architecture}$** <br>\n",
        ": NVIDIA의 향상된 연산용 프로그래밍 프레임워크.<br>\n",
        "\n",
        "> GPU는 단일계산에 대해서는 CPU보다 느릴 수 있음.<br>\n",
        "따라서 데이터가 충분히 크지 않다면 GPU를 사용하는 이득이 별로 없을 수 있음.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "e67skN2zORdn"
      }
    }
  ]
}