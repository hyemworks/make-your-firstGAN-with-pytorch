{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch04-cuda-basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOr9VC7U4JZEUiPPZWmrCJu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyemworks/make-your-firstGAN-with-pytorch/blob/main/ch04_cuda_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbMFrDl4kCqW"
      },
      "source": [
        "# **CHAPTER 04 &nbsp;&nbsp;&nbsp;&nbsp;CUDA Basics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBbFpe1ykJqm"
      },
      "source": [
        "## **Numpy VS Python**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8fG6Ud4kc4W"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_n4w7MykoGy"
      },
      "source": [
        "# ì •ì‚¬ê°í–‰ë ¬ì˜ í¬ê¸°\n",
        "size = 600\n",
        "\n",
        "a = np.random.rand(size,size)\n",
        "b = np.random.rand(size,size) # 0ê³¼ 1ì‚¬ì´ì˜ ì„ì˜ì˜ ê°’ìœ¼ë¡œ ë‘ ë„˜íŒŒì´ í–‰ë ¬ì„ ì±„ì›€."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCoTdeZrk3EX",
        "outputId": "6d872fb4-9c84-46de-eeca-805a75ea47a7"
      },
      "source": [
        "%%timeit\n",
        "# í•œ ì…€ì—ì„œ ì‹œê°„ì´ ì–¼ë§ˆë‚˜ ì˜¤ë˜ ê±¸ë¦¬ëŠ”ì§€ í‘œì‹œí•´ì¤Œ.\n",
        "\n",
        "# 01. numpyë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° - 12.1 ms per loop\n",
        "x = np.dot(a,b)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 12.1 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCH-VsMDlGIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b25e5c-48d9-4598-b52e-6044e309d1d9"
      },
      "source": [
        "%%timeit\n",
        "\n",
        "# 02. numpyë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° - 2min 47s per loop\n",
        "c = np.zeros((size,size))\n",
        "\n",
        "for i in range(size):\n",
        "  for j in range(size):\n",
        "    for k in range(size):\n",
        "      c[i,j] += a[i,k]*b[k,j]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2min 47s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â†ª ê°„ë‹¨íˆ ë¹„êµí•´ë³´ë©´, Numpyê°€ ìˆœìˆ˜ Pythonë³´ë‹¤ **í–‰ë ¬ê³± ê³„ì‚°**ì´ í›¨ì”¬ ë¹ ë¥´ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤!"
      ],
      "metadata": {
        "id": "BfERI1NAcC1U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Kis_HPYklz"
      },
      "source": [
        "## **ì—”ë¹„ë””ì•„ CUDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAWuKPtMYgmC"
      },
      "source": [
        "âœ… **NVIDIA, ì—”ë¹„ë””ì•„**\n",
        "  - GPU ì‹œì¥ì˜ ë¦¬ë”ì—­í• ì„ í•˜ê³  ìˆëŠ” ê¸°ì—…\n",
        "  - ê°•ë ¥í•œ í•˜ë“œì›¨ì–´ ê°€ì† ê¸°ëŠ¥ì„ ê°–ì¶˜, ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ì— í‘œì¤€ì ì¸ ì†Œí”„íŠ¸ì›¨ì–´ íˆ´ì„ ì œê³µí•¨.<br>\n",
        "  <br>\n",
        "  ğŸ¦‹ <b>CUDA</b>$^{Compute-Unified-Device-Architecture}$<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;: ì—”ë¹„ë””ì•„ì—ì„œ ì œê³µí•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ í”„ë ˆì„ ì›Œí¬\n",
        "  <br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;â–¶ ë‹¨ì  <br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: ì—”ë¹„ë””ì•„ì˜ GPUì—ì„œë§Œ ë™ì‘.<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cf) ê²½ìŸì‚¬ì¸ AMDëŠ” ìµœê·¼ì—ì„œì•¼ í•„ì í•  ë§Œí•œ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•¨. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAGmfkWPmJ3y"
      },
      "source": [
        "## **CUDAë¥¼ Pythonì—ì„œ ì‚¬ìš©í•˜ê¸°**\n",
        "\n",
        ": Colab ë…¸íŠ¸ë¶ ë‚´ ì„¤ì •ë°©ë²•<br>\n",
        "â†ª ìƒë‹¨ ë©”ë‰´ > [Runtime] > [Change Runtime Type] > [Hardware Accelerator] > **GPU**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor ë§Œë“¤ê¸°\n",
        "\n",
        "x = torch.FloatTensor([3.5])\n",
        "print(x.type()) # ë°ì´í„° íƒ€ì… ì²´í¬"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ET_KQpaKux-",
        "outputId": "f4958ded-0035-4161-d999-d0490b3c675d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAQrA6Whfsm3",
        "outputId": "1db3938e-1d09-4151-86b2-026d2f7c2d37"
      },
      "source": [
        "# GPUì—ì„œ tensor ë§Œë“¤ê¸°\n",
        "\n",
        "x = torch.cuda.FloatTensor([3.5])\n",
        "print(x.type()) # ë°ì´í„° íƒ€ì… ì²´í¬\n",
        "print(x.device) # ì–´ë–¤ ì¥ì¹˜ì— í…ì„œê°€ ì˜¬ë¼ê°€ ìˆëŠ”ì§€ ì²´í¬\n",
        "x.device  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.FloatTensor\n",
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUë¥¼ í†µí•´ í…ì„œ ê³„ì‚°\n",
        "\n",
        "y = x*x\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZeKn2ktLwyZ",
        "outputId": "b8f40121-fd2d-4e2b-f87a-df233dcca0c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.2500], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "GPUë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì´ë“ì„ ì–»ìœ¼ë ¤ë©´, ì •ë§ ë§ì€ ë°ì´í„°ë¥¼ ê° GPU ì½”ì–´ì— ë‚˜ëˆ ì„œ íˆ¬ì…í•´ì•¼í•¨.<br>\n",
        "â¡ ì•ì—ì„œ í–ˆë˜ í–‰ë ¬ê³±ì„ GPUì—ì„œ í•´ë³´ì"
      ],
      "metadata": {
        "id": "Jx8GvPl5L-MJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugGriYH2f9lj"
      },
      "source": [
        "aa = torch.cuda.FloatTensor(a)\n",
        "bb = torch.cuda.FloatTensor(b)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Omn3CVgwsJ",
        "outputId": "e7393245-942d-42cd-db1b-b3aa23481874"
      },
      "source": [
        "%%timeit\n",
        "\n",
        "# torch.matmul => pytorchì—ì„œ \"í–‰ë ¬ê³±\"ì„ í•˜ëŠ” ëª…ë ¹ì–´\n",
        "\n",
        "cc = torch.matmul(aa,bb)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 480.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 116 Âµs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "ì•„ë˜ ì…€ == íŒŒì´í† ì¹˜ì˜ deviceì— ëŒ€í•œ í‘œì¤€ì ì¸ ì½”ë“œì²˜ë¦¬<br>\n",
        "â–¶ **GPU**ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•˜ê³ , **CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ ì•Šì„ ë•Œ**ì—ë§Œ **CPU**ë¥¼ ì´ìš©í•¨!"
      ],
      "metadata": {
        "id": "byl7uOnPM0zl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8iYJxyfhK1U",
        "outputId": "2e3923da-c57c-47ec-8159-df4a04e8fbf1"
      },
      "source": [
        "## Check if CUDA is available\n",
        "## if yes, set default tensor type to cuda\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "  print(\"using cuda : \", torch.cuda.get_device_name(0))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda :  Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Summary**\n",
        ">âœ… **GPU$^{Graphics-Processing-Unit}$, ê·¸ë˜í”½ ì²˜ë¦¬ ì¥ì¹˜** <br>\n",
        ": ë§ì€ ìˆ˜ì˜ ì—°ì‚° ì½”ì–´ë¥¼ í†µí•´ íŠ¹ì •í•œ ì‘ì—…ì„ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆìŒ.<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; â†ª **ë³‘ë ¬ë¡œ í–‰ë ¬ê³±ì„ ì²˜ë¦¬**í•˜ëŠ” ê²ƒ ë“±ì„ í¬í•¨í•˜ì—¬, ë‹¨ìˆœ ê³„ì‚°ì— íŠ¹í™”ë¨.<br>\n",
        ": ê·¸ë˜í”½ ê´€ë ¨ ì—°ì‚°ì™¸ì—ë„ ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨ ê³„ì‚°ì´ ë¹ ë¦„.\n",
        "<br>\n",
        "<br>\n",
        "âœ… **CUDA$^{Compute-Unified-Device-Architecture}$** <br>\n",
        ": NVIDIAì˜ í–¥ìƒëœ ì—°ì‚°ìš© í”„ë¡œê·¸ë˜ë° í”„ë ˆì„ì›Œí¬.<br>\n",
        "\n",
        "> GPUëŠ” ë‹¨ì¼ê³„ì‚°ì— ëŒ€í•´ì„œëŠ” CPUë³´ë‹¤ ëŠë¦´ ìˆ˜ ìˆìŒ.<br>\n",
        "ë”°ë¼ì„œ ë°ì´í„°ê°€ ì¶©ë¶„íˆ í¬ì§€ ì•Šë‹¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ë“ì´ ë³„ë¡œ ì—†ì„ ìˆ˜ ìˆìŒ.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "e67skN2zORdn"
      }
    }
  ]
}